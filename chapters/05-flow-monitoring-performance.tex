 \chapter{Flow Monitoring Performance}\label{chap:flow-monitoring-performance}

\begin{chapintro}

Intro, flow monitoring on commodity hardware, possibly using HW accelerated NIC.

The paper included in this chapter is~\cite{Velan-2015-High}. Another paper related to this chapter is~\cite{Pus-2015-Hardware}.

The organisation of this chapter is as follows:
\begin{itemize}
  \item Section~\ref{sec:performance-measurement} provides background to the measurement of flow monitoring performance and highlight its pitfalls.
  \item Section~\ref{sec:performance-capture} describes the state of the art of high-speed packet capture, which is an important part of every flow monitoring system.
  \item Section~\ref{sec:performance-hw-acceleration} shows how can the flow monitoring be accelerated with the use of specialized FPGA-based network interface cards.
  \item Section~\ref{sec:performance-sw-optimization} discusses available methods of optimization of flow exporter software.
  \item Section~\ref{sec:performance-high-density} presents a high-density flow monitoring system capable of monitoring of sixteen 10\,Gb links in a single box and evaluates its performance.
  \item Section~\ref{sec:performance-summary} summarizes the chapter.
\end{itemize}

\end{chapintro}

\newpage


\section{Measuring Flow Monitoring Performance}\label{sec:performance-measurement}

The primary goal of measuring flow monitoring performance is to determine whether the system can be deployed to monitor a particular network or a link. For example, if the system is capable of monitoring 20\,Gb/s of traffic, it can be deployed in both directions of a 10\,Gb/s link. However, the claim that the system can handle 20\,Gb/s may mean a lot of different things and it usually differs from vendor to vendor. The throughput of a flow monitoring process depends on a number of factors, such as the configuration of the flow creation process and the type of network traffic that is being monitored. 10\,Gb/s may mean 14.88\,Mpps (millions of packets per second) for minimum Ethernet frames (20\,B + 64\,B) or just 813\,kpps for maximum Ethernet frames on 1500\,MTU (each frame is 1538\,B). The processing of different packet headers can take different time as well, for example, IPv4 vs IPv6 or UDP vs TCP. The number of flows has a large impact on the flow creation process as a flow record must be kept for each of the flows. Therefore, a detailed performance analysis of the flow monitoring system should be performed before its real-world deployment.

The throughput of the flow monitoring system is usually measured either in packets per second or bits per second. However, since the packet size should be reported as well so that these values provide meaningful information, they are mostly interchangeable. Packets per second metric is preferred in most of this chapter.

The goal of this section is two-fold. Firstly, it describes the parameters that need to be specified when reporting on a flow monitoring system performance. There are three different categories of the parameters: hardware configuration, exporter configuration, traffic composition. Secondly, measurement of the impact of optimizations is discussed. Although the impact can be measured simply by an increase in the overall throughput, there are a few pitfalls that need to be recognized and avoided for the results to be interpreted correctly.


\subsection{Measuring Overall Throughput}

The overall throughput of the flow monitoring process depends upon a number of factors. Moreover, there are two methods of measuring the throughput even if all of these factors are set. The first method is to generate the testing traffic at such a rate that is above the capability of the monitoring process to handle. The throughput is then determined as the number of packets that were actually processed by the flow exporter. This method gives an upper bound on the capabilities of the monitoring process and the measurement is quite easy to carry out. However, deploying the flow monitoring system based on such an estimate can easily lead to dropped packets in practice since there is quite a large packet drop associated with the measurement as well. The second method measures throughput without packet loss or with a defined packet loss rate. Given a predetermined packet loss rate, the traffic is generated so that the flow monitoring system performs with lower that given packet loss rate. The throughput is then increased until the packet loss matches the predetermined value and the throughput at that point is considered to be the result of the measurement. Both performance measurement methods are important. The first one gives an upper bound of the capabilities of the flow monitoring process and the second one shows how much traffic can be safely processed with acceptable packet loss.

When evaluating the performance of a flow monitoring process, the hardware on which it runs must be taken into consideration. The performance depends on the frequency of the processor, available instruction sets, and size of caches. When the exporter software is able to utilize multiple threads the number of cores of the processor and the number of processors matter as well. Moreover, when there is more than one processor, the correct use of Non-Uniform Memory Access (NUMA) architecture is important. The buffers of processes and threads running on a one CPU should be in a memory connected to the same CPU. Otherwise, the latency for accessing this memory is increased as the data must be accessed by a memory controller of another process through a bus such, as the QuickPath Interconnect~\cite{IntelCorporation-2009-Introduction} bus or its newer version Ultra Path Interconnect (in case of Intel processors).

The choice of packet capture solution often limits the upper bound on the throughput of the flow monitoring process. Although packet capture is an important part of flow monitoring process, it is used for other tasks as well and is of interest to various researchers~\cite{Garcia-Dorado-2013-High, Nassopulos-2014-Flow}. High-speed packet capture is described in more detail in Section~\ref{sec:performance-capture}.

The configuration of the flow exporter has a great impact on the throughput as well. The active and inactive timeouts significantly affect the number of created flows and flow records~\cite{Hofstede-2014-Flow} which in turn affects the utilization of the flow cache and therefore the total throughput. The flow cache size should be tuned to the expected number of flows so that the data locality is preserved as much as possible. Moreover, the size of flow records depends on the number of extracted properties and it affects the size of the cache as well. The more properties extracted, the larger the flow record. Naturally, the number of extracted properties has a direct impact on the throughput since each property must be extracted and stored in the flow record, which requires computing power and more memory accesses.

One of the most important aspects of throughput measurement is the used dataset. Choosing shortest packets and a single flow allows to benchmark the packet parser, shortest packets and a large number of flows put great stress on the flow cache. Using more complex packets with multiple protocol layers tests the packet parser capabilities and performance as well. The relative sizes of flows in the data set matter as well. When there are a few dominant flows, the corresponding flow records are kept cached and the overall performance increases. However, if the packets of the flows are equally interlaced, the caching of the flow records is limited. Since the choice of the dataset has such an extensive impact on the flow monitoring process and its throughput, it is imperative to choose a correct dataset that supports the intentions of the given benchmark. A guidance for choosing a dataset can be found in the work of the IETF Internet IP Performance Measurement working group~\cite{IESG-1997-IP} and IETF Benchmarking Methodology working group~\cite{IESG-1989-Benchmarking}, especially in~\cite{rfc2330, rfc6985}.

We have argued that there are many factors that influence the throughput of a flow monitoring system. Since it is clearly not possible to test all combinations of the input parameters, it is necessary to choose a set of appropriate settings that cover either the most extreme scenarios or approximate some important real-world scenario. The work of~\citeauthor{Nassopulos-2014-Flow}~\cite{Nassopulos-2014-Flow} shows that performing a measurement using a large number of configurations allows deriving results that can help with the optimization effort. They show that the implementation of the flow cache as well as the composition of the traffic has a large impact on the flow monitoring process. Regardless of the chosen parameters, a proper description of the used configuration and dataset must always accompany all presented results. Therefore, we recommend using a synthetic dataset that can be described in a few simple rules.


\subsection{Measuring an Impact of Optimizations}

Throughput measurement is an integral part of any performance optimization effort. The goal of the measurement, in this case, is two-fold. Firstly, bottlenecks and need to be identified so that the optimization can be effective. For example, if a flow cache lookup takes 70\,\% of the total processing time for a single packet, optimizing packet parser is not very effective. Secondly, the measurement is repeated to examine the effect of a given optimization. Moreover, it is necessary to verify that optimizing for a single use case does not have a negative impact on other use cases. Therefore, a thorough performance measurement is repeated often during any optimization process.

Identifying bottlenecks can be a complicated process. It is often beneficial to measure execution time spent on processing a single packet throughout the flow monitoring process. The authors of~\cite{NETCOPETechnologies-2017-Modelling} show that it is possible to roughly estimate the time required for packet reception and parsing based on several parameters. \citeauthor{Gallenmueller-2015-Comparison} apply a similar methodology to compare the performance of several high-performance packet processing frameworks in~\cite{Gallenmueller-2015-Comparison}. Using a similar process can help to identify bottlenecks in the flow processing as well.

The processing speed of a computer is limited by the speed of the processor and the time required to fetch data from memory. If a computation requires only a small amount of memory that fits in CPU registers or L1 cache, the processor can be fully utilized. However, when a lot of data needs to be processed, there are many uncached accessed to memory with high latency. This causes the CPU utilization to be low. It is therefore very useful to measure the number of instructions per processor cycle (IPC). The higher the IPC, the better the CPU is utilized. When optimizing such a process, the computation should be simplified. However, when the IPC is low, the CPU waits for data from memory. In such a case, optimizing data locality and memory accesses is the best way to improve the performance. 

Since multi-core CPUs are a standard nowadays, a good way to improve performance is to process the data using multiple threads. However, it is important to keep in mind that the bandwidth of CPU memory controller is limited and that passing data between the threads consumes the bandwidth as well. Finding a good balance is often a difficult task which requires experimentation and thorough measurement of the system load.

A good way to understand the relationship between CPU processing power and memory bandwidth is to use Roofline Performance Model~\cite{Williams-2009-Roofline}. Its core parameter is Arithmetic Intensity which is the ratio of total floating-point operations to total data movement. The visualisation of the model shows both the implementation performance limitation and limitations of the used architecture. However, correctly estimating the arithmetic intensity of the flow measurement process is a challenging task.

Optimizations proposed in Sections~\ref{sec:performance-hw-acceleration} and~\ref{sec:performance-sw-optimization} either reduce the amount of processed data or reduce the number of computation steps necessary to process each packet. We also discuss multithreaded flow processing and point out the pitfalls and caveats that can result in incorrect results.


\section{High-Speed Packet Capture}\label{sec:performance-capture}

Packet capture is the first step of the flow monitoring process and has a significant impact on the overall performance. Moreover, as it is an important part of other network applications, such as switching and routing~\cite{Kawashima-2016-Host}, the high-speed packet capture using commodity hardware running Linux operating system has been an active research area in recent years. Since the performance of packet capture directly impacts the performance of the whole flow monitoring process, the aim of this section is to present basic principles and significant technologies in this area. Furthermore, some techniques of the packet capture, such as Receive Side Scaling (RSS), have a direct impact on the functionality of flow monitoring as well.

The goal of high-speed packet capture is to deliver packets from Network Interface Card (NIC) to the user-space application as fast as possible while providing the desired functionality, such as packet fanout to multiple threads and applications. The main difference between high-speed packet capture and standard packet processing in an operating system is that the high-speed packet capture is not connection oriented. It does not provide socket API for applications to easily communicate through. Instead, it allows applications to effectively receive and send raw packets. However, to understand the packet capture process and its limitations, we shortly describe how Linux network stack receives packets, as it is the common starting point of all packet capture frameworks.

\subsection{Linux Network Stack}

The basic function of every NIC is to receive a packet from the network and pass it to the RAM memory, where it is processed further. Direct Memory Access (DMA) is used for the data transfer. The main advantage is that it does not require the cooperation of the CPU and does not consume any CPU cycles. The NIC can access only a limited memory region for which the DMA access is permitted. In the Linux network stack, this region is part of the kernel memory and is not directly accessible to the user-space. The way to notify the kernel of arrival used to be through Interrupt ReQuest (IRQ). However, as the network speed increased to 1\,Gbps speed, full utilization of the network used to cause an interrupt storm -- way too many interrupts for the system to handle efficiently. The original networking stack was replaced by New API (usually called NAPI), which uses polling for high-speed packet reception and falls back to interrupts for lower packet rates. This combination of both interrupt and polling approaches allows to consume CPU cycles for low traffic and avoids interrupt storms for high packet rates. The NAPI was introduced in Linux kernel version 2.4.20 and 2.6.

After the packet is present in RAM and the kernel is notified, either by interrupt or polling, the packet is copied to kernel internal structure called \emph{sk\_buff}. This structure is then pushed to kernel network stack, where it is processed and made available to user applications. However, every call to a system \emph{recv*} function also needs to provide a pointer to an user-space buffer to which the data are copied. Therefore, the packet is copied twice by the kernel, as demonstrated in Figure~\ref{fig:NAPI_no_MMAP}.

\begin{figure}[!tb]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \includegraphics{figures/NAPI}
        \caption{Without PACKET\_MMAP feature}
        \label{fig:NAPI_no_MMAP}
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth}
        \includegraphics{figures/NAPI_MMAP}
        \caption{With PACKET\_MMAP feature}
        \label{fig:NAPI_MMAP}
    \end{subfigure}
    \caption{Packet transition through memory in Linux NAPI.}
    \label{fig:NAPI}
\end{figure}

The Linux network stack (with \emph{sk\_buff}) cannot be used for packet capture because the stack takes care of all layers of the packets and delivers only the application content to the application. However, there is an option to use raw packets where the application receives and sends complete packets with all headers, including the Ethernet. The reception of raw packets uses a different structure than the \emph{sk\_buff}, however, two copy operations are needed for each packet as well. Apart from the excessive copying of the packets, there is another significant performance hit. The standard API for working with packets requires performing a system call for reception of each packet (two calls when a timestamp is needed as well). Moreover, it is not possible to utilize the RSS feature provided by some NICs and process packets independently on multiple cores.

To provide an efficient way to perform packet capture using standard Linux kernel and drivers, \emph{PACKET\_MMAP}~\cite{LinuxKernelOrganization-2017-PACKETMMAP} feature was added to the kernel. It utilizes a shared buffer between the kernel and the user-space which alleviates the need to copy the packet for the second time, as shown in Figure~\ref{fig:NAPI_MMAP}. Moreover, the number of packets that can be read in a single batch is not limited, which significantly lowers the number of necessary system calls and thus improves performance. Another advantage of the PACKET\_MMAP feature is that the processing of packets can be performed by multiple threads. The distribution of packets can be performed using a hash, round robin, random selection, and several other policies. 

Although the Linux NAPI has evolved to support fast packet handling, there are several important performance limitations left:
\begin{itemize}
  \item The packets are copied from DMA memory region to the user-space accessible buffers.
  \item There is no support for RSS (Receive Side Scaling).
  \item There is no support for NUMA architecture awareness.
\end{itemize}

There are several frameworks that aim to remove these limitations to achieve the highest possible throughput for packet I/O operations.


\subsection{High-Speed Packet I/O Frameworks}

Although there were several works analysing the performance packet capture applications, such as~\cite{Degioanni-2003-Profiling}, one of the first alternatives to using the Linux network stack for packet capture was \emph{PF\_RING}. The PF\_RING socket was created by \citeauthor{Deri-2004-Improving} and its first description appeared in~\cite{Deri-2004-Improving}. The PACKET\_MMAP was very new at that time and some of the introduced features, such as memory mapping overlapped. However, the PF\_RING had several advantages. Firstly, the packets were not queued into kernel network structures at all. It meant, that they were not available to standard applications using socket API but only to applications that used the PF\_RING sockets. Secondly, packet sampling was implemented at a lower level, which meant that sampled packets were not even passed to upper layers. Lastly, multiple applications were able to simultaneously open several PF\_RING sockets without interference. However, the main performance limitations remained the same as with Linux NAPI.

The problem with unnecessary copying between DMA-able memory and the shared buffer was already solved when a specialized NICs with custom drivers were used. One of the most used cards for this purpose was the DAG NIC~\cite{UniversityWaikato--Dag} which was eventually commercialized by the Endace~\cite{ETL--Endace} company. The DAG NIC used FPGA chip that could be programmed to provide specific functionality, such as high-precision packet timestamping. Moreover, it meant that it was possible for the driver to instruct the card to upload packets in a correct format directly to the buffer that was shared to the user-space. \citeauthor{Degioanni-2004-Introducing} used this approach and proposed a design for distributing packets to multiple threads to better utilize CPU parallelism~\cite{Degioanni-2004-Introducing}. However, the card did not support RSS and thus the single buffer to which the NIC uploaded the packets remained to be a bottleneck.

To eliminate unnecessary packet copying even without the use of a specialized NIC, \citeauthor{Deri-2005-nCap} developed a new framework called nCap in \citeyear{Deri-2005-nCap}. The most important innovation was that the standard kernel packet processing was completely bypassed. A specialized driver was developed for compatible NICs (Intel 1\,GE and 10\,GE adapters were supported) that allowed the NIC to directly manage the packet reception and transmission buffers. These buffers were then mapped directly to user-space and a user-space library called nCap is used to manage these buffers. This \emph{zero copy} approach, shown in Figure~\ref{fig:zero_copy}, is used in almost all other high-speed packet frameworks as well. The main disadvantage is that it requires specialized or at least modified drivers and a supported NIC. The direct access to packet buffers filled by the NIC was eventually combined with PF\_RING into the PF\_RING DNA~\cite{ntop-2010-PFRING} (Direct Memory Access) framework. The disadvantage of this approach is that only one application at a time can access the packet buffer.

\begin{figure}[!tb]
  \begin{center}
    \includegraphics{figures/zero_copy}
  \end{center}
  \caption{Packet transition through memory using a zero copy approach.}
  \label{fig:zero_copy}
\end{figure}

When commodity NICs started to support Receive Side Scaling (RSS), the packet capture frameworks started supporting this feature to better utilize multi-core CPUs. \citeauthor{Fusco-2010-High} showed how RSS can be utilized by multi-threaded polling together the zero copy approach~\cite{Fusco-2010-High} in~\citeyear{Fusco-2010-High}. The basic idea was to use one kernel polling thread for each receive (RX) queue and make the associated buffer available to one user-space capture thread. This approach, called \emph{TNAPI}, was used together with the PF\_RING framework and utilized a custom driver for zero copy packet reception. The authors show that it is important to correctly configure the system to work on NUMA architecture by setting CPU affinity of the individual polling and packet capture threads. Therefore, this approach mitigates the limitations of Linux NAPI discussed in the previous section. 

The development of PF\_RING, nCap, DMA, and TNAPI frameworks resulted in the creation of the \emph{PF\_RING ZC (Zero Copy)} framework~\cite{ntop--PFRING}. It uses proprietary drivers to deliver packets to PF\_RING using the zero copy approach, supports RSS and NUMA architecture to spread packet processing across multiple CPU cores and threads, and allows the kernel networking stack to process packets when no PF\_RING aware application is running. Moreover, by managing the PF\_RING in the kernel, it supports packet fanout for multiple user-space applications and even virtual machines. The PF\_RING ZC also allows user-space applications to receive packets in bursts (batches), which was not possible in vanilla PF\_RING. This feature allows to reduce the number of system calls and significantly helps to increase performance, especially when mitigations to Meltdown and Spectre attacks made syscalls more expensive~\cite{Gregg-2018-KPTIKAISER}.

\emph{PFQ} and \emph{netmap} packet capture frameworks were published 2012. Around the same time, Intel started public development of the \emph{Data Plane Development Kit}. The \emph{PFQ} packet capturing engine was introduced by \citeauthor{Bonelli-2012-Multi} in~\cite{Bonelli-2012-Multi}. PFQ supports RSS, both vanilla and modified drivers (for zero copy operation), and utilizes packet processing within NAPI context. The transition of packets from kernel-space to user-space is implemented by a wait-free queue. When packets need to be copied, it is done in batches which increases performance. The authors showed that the performance of PFQ is better than that of vanilla PF\_RING in their setup. PFQ has evolved significantly in the recent years. The authors added many features~\cite{Bonelli-2014-Purely, Bonelli-2016-Network, Bonelli-2017-Enabling}, such as support for in-kernel programmable early processing and user-space parallel processing while preserving normal host system network stack operation.

The \emph{netmap} framework developed by ~\citeauthor{Rizzo-2012-Netmap} is different from PF\_RING and PFQ in a fundamental way. The packets are not stored in continuous buffers but rather in separately allocated buffers of fixed sizes. It allows passing packets between interfaces in a zero-copy manner. Moreover, a user-space application can exchange packets with the NIC and the host networking stack independently. This design is useful for applications such as packet routing and forwarding.

Intel's \emph{Data Plane Development Kit}~\cite{LFP--Data} known simply as \emph{DPDK} is set of libraries and drivers for fast packet processing. After Intel started the project, it's governance came under the Linux Foundation Project, which unites many companies that contribute to the project. Similarly to netmap, it uses discretely allocated packet buffers instead of buffer ring. However, user-space communicates directly with the card to eliminate unnecessary system calls. Therefore, when a driver with DPDK support is loaded, the NIC cannot be used together with the standard kernel networking stack. By utilizing per packet buffers DPDK allows processing packets out of sequence, which is useful for example for a selective packet capture. Matching packets can be retained while others can be quickly discarded. This is not possible with ring buffer approach without packet copying. DPDK does not support interrupts, therefore packets are always polled from the NIC. This is effective to high loads, however, it excessively utilizes the CPU for lower packet rates. DPDK is widely supported and specialized drivers exist for many NICs from different vendors~\cite{LFP--DPDK}. 

There are other packet capture and manipulation frameworks that were not discussed in this section, such as OpenOnload~\cite{Mansley-2008-Getting} from Solarflare and PacketShader I/O~\cite{Han-2010-PacketShader} using GPU acceleration to build fast router. Moreover, manufacturers of (FPGA-based) high-speed NICs such as Endace, Napatech, Myricom, Mellanox Technologies, or Netcope Technologies provide their own drivers and libraries for fast packet processing together with their products. These drivers and libraries utilize very similar if not the same approaches as the ones described in this section.

There are several works comparing the performance of different packet capture frameworks. They can be used as a reference when choosing the correct framework for a certain use case. \citeauthor{Braun-2010-Comparing} evaluate the performance of native FreeBSD and Linux packet capture together with PF\_RING on Linux~\cite{Braun-2010-Comparing}. They identify bottlenecks and provide guidelines for debugging loss of performance. The authors of~\cite{Garcia-Dorado-2013-High} not only compare the performance of PacketShader, PFQ, and PF\_RING, but they also provide a detailed description of these frameworks and of Linux NAPI as well. \citeauthor{Wang-2016-Comparison} compare PF\_RING, PF\_RING ZC, and DPDK frameworks in~\cite{Wang-2016-Comparison}. The focus of this comparison is on the correct utilization of the NUMA architecture. The authors conclude that the difference in thread assignment between the compared frameworks has an impact on the overall performance. However, they fail to realize that processing on one of the NUMA nodes must be naturally faster since the NIC is directly connected only to this one node. The authors of~\cite{Barbette-2015-Fast} not only compare features and performance of PACKET\_MMAP, PacketShader I/O, netmap, PF\_RING ZC, and DPDK, they also analyse the use of these frameworks with modular router Click. The extensively discuss the impact of important features such as I/O batching, ring size, execution model, zero-copy, and multi-queuing on the final performance of the Click router. Finally, \citeauthor{Gallenmueller-2015-Comparison} propose a model to estimate and assess the performance of various packet processing frameworks in~\cite{Gallenmueller-2015-Comparison}. They apply the model to DPDK, netmap, and PF\_RING ZC. They assess the transmission efficiency, the influence of caches, the influence of batch sizes, and latency for each framework.

% TODO framework comparison table: take from \cite{Barbette-2015-Fast} and add PFQ?


\section{Hardware Acceleration in Flow Monitoring}\label{sec:performance-hw-acceleration}

\itodo{Survey of flow caches in hardware, unsuitable for application monitoring}
% mostly for basic flow monitoring, but for the SDM

We have shown that there are many different challenges when building application flow monitoring system. Most of the described processes are performance sensitive, especially packet reception, packet parsing, and flow aggregation. To achieve application flow monitoring throughput of tens of gigabits per second, several optimization and acceleration techniques can be applied. This section focuses on these techniques. Note that we avoid the use of sampling since it degrades the quality of exported data, as shown by the authors of~\cite{Brauckhoff-2006-Impact}. Although we describe acceleration techniques, their design, and main ideas, we will not go into details about their evaluation and testing, which is out of the scope of this article. 

It has been shown by the authors of~\cite{Velan-2015-High} that standard flow monitoring can achieve more than 100 Gb/s throughput on a commodity CPU when hardware accelerated NICs are used. The work of \citeauthor{Kekely-2016-Software}~\cite{Kekely-2016-Software} shows that it is possible to utilize these NICs to achieve 100 Gb/s throughput even for application flow monitoring. We discuss both hardware accelerated techniques and software optimizations in this section. Table~\ref{tab:flow-acc-techniques} gives an overview of the discussed techniques.

% TODO abolish or update the table, it needs to point to the next section as well. It should probably contain only approaches for this section, maybe show as usable for basic/application flow monitoring
% TODO similar table in the next section
\begin{table}[ht!]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Hardware acceleration} & \textbf{Software acceleration} \\ \hline
    Multiple reception buffers & Multithreading \\
    Packet trimming & NUMA awareness \\
    Packet header preprocessing & Flow state in parsers \\
    Flow processing offloading & Flow cache design \\
    Application identification & Flow cache timeouts \\ \hline
    \end{tabular}
    \caption{Flow Acceleration Techniques}
    \label{tab:flow-acc-techniques}
\end{table}


A field-programmable gate array (FPGA) is usually used in hardware accelerated network interface cards. It allows to parse packet headers and perform other tasks such as packet trimming or computing hashes to identify flows in the NICs. It usually supports transferring data to multiple buffers in RAM so that the software can efficiently use a multi-threading model. There are several manufacturers that provide such NICs, such as Napatech, Myricom, Mellanox Technologies, or Netcope Technologies. NICs can support hardware acceleration even without an FPGA chip, however, the capabilities are usually more limited and cannot be extended after the card is produced. For example, Intel produces many NICs without an FPGA chip that provide basic hardware acceleration such as packet hashing and transport to multiple RAM buffers.

By transferring data to multiple buffers in RAM, the NIC allows multiple CPU cores to process the data without any kind of locking mechanism. The data parsing is usually the most CPU intensive part of the application flow creation process, therefore it is very desirable to parallelize the computation. It is often necessary for the application packet parsing process to see multiple packets from the same flow. Therefore, it is desirable to store packets belonging to single flow to a single buffer in RAM, so that they are not processed by multiple different threads. To achieve this, the NIC must be able to correctly categorize packets belonging to the same flow. However, it is not necessary for the NIC to differentiate between every flow record. For example, when eight buffers are used, each flow must be sent to exactly one of the buffers. The easiest way to achieve this is to compute a three-bit hash from some of the flow-defining fields in the packet headers. IP addresses and transport layer ports are often used for this purpose, however, most manufacturers do not realize that this works incorrectly for fragmented packets. Therefore, it is better, in most scenarios, to use only IP addresses to distribute the flows to different buffers. The performance improvement achieved when using multiple buffers is directly related to the number of buffers. However, too many buffers introduce a high load on a memory controller causing the performance to be degraded. It is best to experiment with different numbers of buffers to find an optimal value for the target system. We have achieved the best results with 8-16 buffers, depending on the specific scenario and the number of CPU cores.

Memory throughput can easily become a bottleneck when data from 100\,Gb/s link are sent to RAM. One of the options to reduce the amount of processed data is to trim the received packets. Flow measurement without application protocols requires only packet headers up to the transport layer. Capturing the first 100 bytes of each packet is usually enough to contain various MPLS, VLAN, Ethernet, IPv6, and TCP headers. The rest of the packet can be discarded. The performance improvement achieved by this method depends on the average length of processed packets. However, application flow measurement requires also the packet payload. The amount of data that can be discarded varies depending on the measured application protocols. Unless the NIC has additional knowledge about measured traffic, it should not trim the packets at all for application flow measurement.

More radical way to save memory bandwidth and CPU cycles is to let the NIC extract the information required for flow monitoring and send only a special message with this information to the RAM. This process requires very specialized FPGA-based cards, such as COMBO series from CESNET. The performance gain can be quite high, as shown in~\cite{Velan-2015-High}. However, this method is not applicable for application flow measurement since application layer parsing is too complex and dynamic to be fully handled in the FPGA.

Packet trimming and packet parsing in the NIC are not usable for application flow monitoring. The main reason is that application layer parsing needs to be done in software. However, most packets do not carry application protocol headers. These packets can be processed by NIC and only extracted information transferred to software. Such a solution is proposed in~\cite{Kekely-2016-Software} and is called Software Defined Monitoring (SDM). It is based on offloading of heavy flows to the NIC. The important information from application layer is usually transferred in first N packets, where N can be expected to be lower than 20 in most cases. Therefore, after the software processing encounters the Nth packet, it instructs the NIC to process the rest of the flow. Only aggregated information about the flow is sent from NIC to software. The flow cache in the NIC is rather limited in comparison to the amount of RAM available in the software. However, only heavy flows need to be kept in this cache and it can be expired more often to reduce memory requirements. The authors show that 85 percent of traffic is observed in five percent of heavy flows. Therefore, the benefit of SDM has been shown to be an aggregation of 85 percent of packets to flow records in the NIC. This significant acceleration allows application flows to be monitored on 100\,Gb/s traffic. However, there is a downside to the SDM as well. Once a flow is offloaded to NIC, software parsers cannot observe further payloads containing subsequent application headers. For example, in the case of HTTP protocol the HTTP pipelining cannot be detected and information about further requests and responses in the same connection is lost.

Since only a small portion of all packets carry important application protocol information, it is beneficial to recognize such packets in the NIC and mark them for further processing in software. As the NIC cannot do complex application header processing, only a simple mechanism, such as pattern matching, can be utilized for packet classification. The work of the WAND Research Group~\cite{Alcock-2012-libprotoident} shows that it is possible to achieve reasonable traffic classification accuracy using only the beginning of a packet payload. Once the packets carrying application protocol headers are marked, the software parsers can process only these important packets. Moreover, other packets can be trimmed or parsed in the NIC and only important information can be passed for processing in the software. Packet classification can also benefit the SDM. When a flow is offloaded to NIC and a packet with application protocol header is matched, the processing of such a flow can be returned to the software. This approach would efficiently solve the abovementioned problem of HTTP pipelining. The accuracy and usability of pattern matching for packet classification depend on target application protocols and resource limitation of the NIC as well. Further research is needed to determine whether this method can be used for real world application flow monitoring.

\section{Flow Exporter Software Optimization}\label{sec:performance-sw-optimization}
\itodo{do not forget biflow}
\itodo{Flow expiration process - describe how flowmonexp does it and theoretical reasoning why it works quite well. Include some math to explain the ratios}
\itodo{Single packet flows can be handled separately, described by Rick and other papers}
\itodo{Flow termination per application - application specific timeouts~\cite{Rodriguez-2013-Empirical}}
\itodo{Opt-out flow processing - plugins can say whether they want to see a specific flow anymore}

The performance of flow monitoring can be greatly enhanced by offloading as much of the necessary packet processing as possible to the NIC. However, to build a high-performance flow monitoring solution the software processing must be carefully tuned as well. Moreover, the FPGA-based NICs are much more expensive than commodity NICs and cannot always be deployed. This section focuses on flow monitoring optimizations that can be achieved by careful software design and system configuration.

The development of modern CPUs has a tendency to substitute raw power (frequency) by a higher number of CPU cores. To fully utilize the potential of a multi-core CPUs and achieve high flow monitoring performance, it is necessary to create multithreaded flow monitoring software. For NICs that support storing data in multiple buffers in RAM, the solution is to have different threads process the packets from different buffers. The resulting flow records are aggregated either in a single flow cache or in multiple flow caches, one per each thread, as shown in Figure~\ref{fig:exporter-thread-schema}. In either case, it must be ensured that there is a single thread used for exporting the resulting flow records where the data from multiple processing threads are merged. The latter approach is more effective as it clearly prevents the flow cache to become a point of contention. However, when there are multiple flow caches, it is necessary to ensure that each flow is aggregated in a single flow cache. This is ensured by having the NIC correctly distribute the packets to the buffers according to their association with their respective flow. Special care needs to be taken when the application protocol parsers need to process reverse flows as well. Both directions of the communication must be processed by the same thread. Using this approach, $N+2$ threads in case the first case or $2N+1$ threads in the second case can be utilized, where $N$ is the number of buffers and the last thread is used for flow export. 

\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=\textwidth]{figures/exporter-thread-schema}
  \end{center}
  \caption{Multithreaded flow measurement with separate flow cache: a) single flow cache; b) multiple flow caches.}
  \label{fig:exporter-thread-schema}
\end{figure}

Separating packet parsing from flow cache management increases performance, however, processing application protocols may require a state of the connection to be kept. In such a case the flow cache record must be made available to the packet processing thread, which results in a use of synchronization primitives and overall performance decrease. One possible solution to this problem is to keep a different, smaller cache for chosen flow records directly in the packet processing thread. The only communication between the packet processing thread and the flow cache thread is a one-way passing of flow records, which can be done very effectively.

When a server with multiple CPUs is used, it is necessary to take care to assign each thread to correct CPU core. When the data is uploaded to RAM physically connected to different CPU than the packet processing core is running on, there is a performance hit for accessing the local memory of that CPU.

It is not effective to try every available application header parser on every packet to see which one is able to process it. When a packet from a flow was already matched by some application parser, it will usually not be matched by others. Therefore, by keeping the information about which flow is to be processed by each parser, most of the unnecessary and possibly expensive calls to application parsers can be eliminated. Moreover, when the flow is yet unmatched by any application parser, it is best to execute the application protocol parsers from the most common to the least common protocol.

One of the most performance critical parts of any flow measurement software is a flow cache. The cache needs to be designed to hold hundreds of thousands of flow records, do fast inserts, updates, and manage record expiration after active and inactive timeouts. It also needs to be robust and resilient enough to handle excessive workloads during DDoS attacks~\cite{Sadre-2012-Effects}. The flow cache design has been studied in the literature, for example in\cite{Wang-2011-Memory, Nassopulos-2014-Flow}. Although authors propose to use various data structures such as linked lists, trees, or multidimensional hashing table, our experience shows that the simplest solution is the best. The flow cache has to maintain data locality to make good use of CPU caches, therefore the dynamic structures do not perform as well as a simple hash table.

Flow cache inactive timeout expiration has a large impact on the performance, as shown in~\cite{Rodriguez-2013-Empirical, Molina-2006-Design}. The flow cache needs to be checked periodically to find and expire inactive records. However, doing the periodic checking in a separate thread requires extensive flow cache locking, which hinders the performance. Therefore, it is more efficient to dedicate part of the processing time of the flow cache thread itself to search for the inactive records. Carefully balancing the flow cache management tasks is a complex problem which offers a considerable potential for further research.

There are many other optimizations that can be performed to increase application flow monitoring performance, such as efficient flow key computation, processing packets in batches, ensuring CPU cache line alignment of flow records and so on. However, they are mostly a code micro-optimization no different from fine-tuning any other high-performance application and are out of the scope of this article.

%TODO split the anove text into the following subsections, or just have it all together
\subsection{Basic Flow Monitoring}

\subsection{Application Flow Monitoring}
\itodo{Speedup by omitting SSL/TLS processing for most application plugins}
\itodo{SW optimization: copy whole packet and parse during flow export in a separate thread - HTTP}




\section{High-Density Flow Monitoring}\label{sec:performance-high-density}
\itodo{TODO: Put in paper from IM2015}
\itodo{Say which throughput measurement method is used (sec 1)}
\itodo{What happens when processing is too slow? Which packets are dropped?}
\itodo{Measurement interference on 10x10G, need to drop on DMA, not input}

\section{Summary}\label{sec:performance-summary}